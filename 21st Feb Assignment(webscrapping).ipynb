{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2e3ca3-093a-44ef-9d61-d7596dcb471b",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "    Web scraping is an automatic method to obtain large amounts of data from websites. Most of this \n",
    "    data is unstructured data in an HTML format which is then converted into structureddata in a \n",
    "    spreadsheet or a database so that it can be used in various applications. There are many \n",
    "    different ways to perform web scrapping to obtain data from websites. These include using \n",
    "    online services, particular API's or even creating our code for web scraping from scratch. \n",
    "    \n",
    "    Web Scrappers can extract all the data on particular sites or the specific data that a user\n",
    "    wants.Ideally, it's best if we specify the data we want so that the web scrapper only extracts\n",
    "    that data quickly. It use to extract specific data easily from websites.\n",
    "    \n",
    "    Three areas where Web Scraping is used to get data:-\n",
    "    1. News Monitoring:- Web scraping news sites can provide detailed reports on the current news\n",
    "        to a company. This is even more essential for companies that are frequently in the news or\n",
    "        that depend on daily news for their day-to-day functioning. After all, news reports can \n",
    "        make or break a company in a single day!\n",
    "        \n",
    "    2. Email Marketing:- Companies can also use Web scraping for email marketing. They can collect \n",
    "        Email ID's from various sites using web scraping and then send bulk promotional and \n",
    "        marketing Eamils to all the people owing these Email ID's.\n",
    "        \n",
    "    3. Price Monitoring :- Web Scraping can be used by companies to scrap their products and \n",
    "        competing products as well to see how it impacts their pricing strategies. Companies can \n",
    "        use this data to fix the optimal pricing for their products so that they can obtain\n",
    "        maximum revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfea2f2-e0ae-47ae-a864-392e241347ca",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "    Different mehods used for web scraping are:\n",
    "    Manual Scraping:\n",
    "    Copy-Pasting : In mannual scraping, what we do is copy and paste web content. This is time\n",
    "    consuming and repetitive and begs for a more effective means of web scraping. It is however\n",
    "    very effective because a website's defences are targeted at automated scraping and not manual\n",
    "    scraping techniques.\n",
    "    \n",
    "    Automated Scraping \n",
    "    \n",
    "    1. HTML parsing: It is done with JavaScript and targets linear or nested HTML pages. It is a \n",
    "        fast and robust method that is used for text extraction, screen scraping, and resource\n",
    "        extraction among others.\n",
    "    2. DOM parsing: DOM is short for Document Object Model and it defines the style structure\n",
    "        and content of XML files. Scrapers make use of DOM parsers to get an in-depth view of\n",
    "        a web page's structure. They can also use a DOM parser to get nodes containing information\n",
    "        and then use a tool like XPath to scrape web pages.\n",
    "    3. Vertical Aggregation: Vertical aggregation platforms are created by companies with access \n",
    "        to large scale computing power to target specific verticals. Some companies run the \n",
    "        platforms on the cloud. Bots creation and monitoring for specific verticals are done\n",
    "        by these platforms without any human intervention. The quality of the bots is measured \n",
    "        based on the quality of data they extract since they are created based on the knowledge\n",
    "        base for the specific vertical.\n",
    "    4. XPath : XML Path Language is a query language that is used with XML documents. XPath can\n",
    "        be used to navigate XML documents because of their tree-like structure by selecting \n",
    "        nodes based on different parameters. XPath can be used together with DOM parsing to \n",
    "        scrape an entire web page.\n",
    "    5. Google Sheets: Google sheets are a web scraping tool that is quite popular among web \n",
    "        scrapers. From within sheets, a scraper can make use of IMPORT XML (,) function to scrape\n",
    "        as much data as is needed from websites. This method is only useful when specific data \n",
    "        or patterns are required from a website. We can also use this command to check if your \n",
    "        website is secure from scraping.\n",
    "    6. Text Pattern Matching: This is a matching technique that involves the use of the UNIX \n",
    "        grep command and is used with popular programming languages like Perl or Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866bacc8-864e-45da-bf20-0d04cbe089aa",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "    Beautiful Soup is a Python package for parsing HTML and XML documents (including having\n",
    "    malformed markup, i.e. non-closed tags, so named after tag-soup). It creates a parse tree\n",
    "    for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n",
    "    \n",
    "    Beautiful Soup is used for parsing web pages and XML.It is used in conjuction with urllib or \n",
    "    the requests package in python in order to extract required information from a website represented\n",
    "    by it's url."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f2b46-d189-49b2-b3f5-4c635f2f1cd5",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "    We use flask in web scraping :\n",
    "    Flask is a lightweight framework to build websites. We'll use this parse out collected\n",
    "    data and display it as HTML, in a new HTML file. The requests module allows us to send\n",
    "    http requests to the website we want to scrap. The first line imports the Flask class \n",
    "    and the render_template method from the flask library. The seco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610cc61-a98d-45c3-bdf6-48d109d5737e",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "    AWS service used in this project are:\n",
    "    1. Code Pipeline : AWS CodePipeline is a continuous delivery service we can use to model, \n",
    "        visualize, and automate the steps required to release our software. We can quickly model \n",
    "        and configure the different stages of a software release process. CodePipeline automates\n",
    "        the steps required to release your software changes continuously. \n",
    "        \n",
    "    2. AWS elastic Beanstalk : This AWS service supports running and managing web applications. \n",
    "        Elastic Beanstalk allows for the easy deployment of applications from capacity \n",
    "        provisioning, load balancing, and auto-scaling to application health monitioring. It \n",
    "        helps to manage peaks in workloads and traffic with minimum costs. Basically, AWS Elastic\n",
    "        Beanstalk is a developer-friendly tool since it manages servers, load balancers, firewalls,\n",
    "        and networks simply. As a result, this service allows developers to show much more focus\n",
    "        on coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653cd238-a8bb-4a4e-84e0-433a5dda8af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
